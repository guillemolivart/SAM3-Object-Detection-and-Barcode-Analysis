{ 
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a43733-0e33-41b3-a690-8179536eb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90210569-e2b3-40f7-8c31-d7a3946259f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b31625-c264-4335-9daa-bfec99ac5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sam3\n",
    "from sam3 import build_sam3_image_model\n",
    "from sam3.model.box_ops import box_xywh_to_cxcywh\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "from sam3.visualization_utils import draw_box_on_image, normalize_bbox, plot_results\n",
    "\n",
    "sam3_root = os.path.join(os.path.dirname(sam3.__file__), \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64421c3-a242-4cf4-a8af-cd80e673f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b8bc71e-0d50-4c9a-a27c-cb6b4abdc19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_path = f\"{sam3_root}/sam3/assets/bpe_simple_vocab_16e6.txt.gz\"\n",
    "model = build_sam3_image_model(bpe_path=bpe_path)\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e339257-ac95-497f-819e-8cb87824b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_barcode(img, mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "\n",
    "    # Gives the rotated bounding box\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    center, size, angle = rect\n",
    "    center, size = list(center), list(size)\n",
    "\n",
    "    # Horizontal Photo\n",
    "    if size[0] < size[1]: # width < height\n",
    "        angle = angle + 90\n",
    "        size[0], size[1] = size[1], size[0] \n",
    "    \n",
    "    M = cv2.getRotationMatrix2D(tuple(center), angle, 1.0)\n",
    "    \n",
    "    dst_w, dst_h = int(size[0]), int(size[1])\n",
    "        \n",
    "    rotation = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))\n",
    "    \n",
    "    barcode = cv2.getRectSubPix(rotation, (dst_w, dst_h), tuple(center))\n",
    "    \n",
    "    return barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef9d438-2e46-4d59-921f-86cbbaf2d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried decoding directly from the image raw data. It didn't work because of the bad image resolution.\n",
    "def bar_value(img):\n",
    "    img = cv2.resize(img, None, fx = 4, fy = 2, interpolation = cv2.INTER_CUBIC)\n",
    "    binary = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 81, 4)   \n",
    "    #display(Image.fromarray(binary))\n",
    "\n",
    "    h, w = binary.shape\n",
    "    center_y = h // 2\n",
    "    row = binary[center_y, :] \n",
    "\n",
    "    segments = []\n",
    "    current_val = row[0]\n",
    "    count = 0\n",
    "    \n",
    "    for pixel in row:\n",
    "        if pixel == current_val:\n",
    "            count += 1\n",
    "        else:\n",
    "            segments.append({'w': count, 'c': \"White\" if current_val == 255 else \"Black\"})\n",
    "            count = 1            \n",
    "            current_val = pixel  \n",
    "    segments.append({'w': count, 'c': \"White\" if current_val == 255 else \"Black\"})\n",
    "    if segments[0]['c'] == \"Black\": segments.pop(0)\n",
    "    if segments[-1]['c'] == \"Black\": segments.pop()\n",
    "    segments.pop(0)\n",
    "    segments.pop()\n",
    "\n",
    "    widths = []\n",
    "    for s in segments:\n",
    "        w = float(s['w'])\n",
    "        \n",
    "        if s['c'] == \"Black\":\n",
    "            w = w + 4.0 \n",
    "        else:\n",
    "            w = w - 4.0\n",
    "            if w < 0.1: w = 0.1 \n",
    "        widths.append(w)\n",
    "\n",
    "    valid_widths = [w for w in widths if w > 5] \n",
    "\n",
    "    sorted_widths = sorted(valid_widths)\n",
    "    \n",
    "    take_n = max(1, len(sorted_widths) // 10) # 10% of the most small lines, we exclude the noise\n",
    "    smallest_sample = sorted_widths[:take_n]\n",
    "    \n",
    "    unit_width = np.mean(smallest_sample)\n",
    "\n",
    "    code = []\n",
    "    for w in valid_widths:\n",
    "        num_modules = int(round(w / unit_width))\n",
    "        \n",
    "        if num_modules < 1: num_modules = 1\n",
    "        if num_modules > 4: num_modules = 4\n",
    "        \n",
    "        code.append(num_modules)\n",
    "\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473c65f4-678d-437d-a184-98c730053627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(input_image, text_prompt, word):\n",
    "    image = input_image.convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "    processor = Sam3Processor(model, confidence_threshold=0.5)\n",
    "    inference_state = processor.set_image(image)\n",
    "    \n",
    "    # 1. Detect and Identify the objects requested by the user on the image: #\n",
    "    objects = [x.strip() for x in text_prompt.split(\",\")]\n",
    "    if objects == [\"all\"] or text_prompt == \"\": objects = [\"item\"]\n",
    "    \n",
    "    img0 = input_image.convert(\"RGBA\")\n",
    "    layer = Image.new(\"RGBA\", img0.size, (0, 0, 0, 0))\n",
    "    draw = ImageDraw.Draw(layer)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 40)\n",
    "    \n",
    "    box_map = {}\n",
    "    \n",
    "    for i, obj in enumerate(objects):\n",
    "        # COLOR\n",
    "        rgb = colorsys.hsv_to_rgb(i / len(objects), 1.0, 1.0) \n",
    "        r, g, b = int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255)\n",
    "        color = (r, g, b) \n",
    "    \n",
    "        # BOX\n",
    "        processor.reset_all_prompts(inference_state)\n",
    "        inference_state = processor.set_text_prompt(state = inference_state, prompt = obj)\n",
    "        boxes = inference_state[\"boxes\"]\n",
    "        scores = inference_state[\"scores\"]\n",
    "        masks = inference_state[\"masks\"]\n",
    "        for j, box in enumerate(inference_state[\"boxes\"]):\n",
    "            \n",
    "            if objects == [\"item\"]:\n",
    "                rgb = colorsys.hsv_to_rgb(j / len(boxes), 1.0, 1.0) \n",
    "                r, g, b = int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255)\n",
    "                color = (r, g, b)\n",
    "            \n",
    "            x1, y1, x2, y2 = box[0].item(), box[1].item(), box[2].item(), box[3].item()\n",
    "            # box_map[f\"{obj}_{j}\"] = (x1, y1, x2, y2) If there is more than one object of the same class\n",
    "            box_map[f\"{obj}\"] = (x1, y1, x2, y2)\n",
    "\n",
    "            draw.rectangle((x1, y1, x2, y2), outline = color, width = 5)  \n",
    "            \n",
    "            # MASK\n",
    "            mask_data = masks[j].cpu().numpy()            \n",
    "            mask_data = (mask_data > 0).astype('uint8') * 255\n",
    "            if mask_data.ndim > 2: mask_data = mask_data[0]   \n",
    "            mask_image = Image.fromarray(mask_data, mode = \"L\") \n",
    "            solid_color = Image.new(\"RGBA\", img0.size, color + (100,)) \n",
    "            layer.paste(solid_color, (0,0), mask_image)\n",
    "    \n",
    "            # TEXT\n",
    "            score = scores[j].item()\n",
    "    \n",
    "            label = f\"{obj} {j} ({score:.2f})\"\n",
    "            text_bbox = draw.textbbox((x1, y1-5), label, font = font)\n",
    "            draw.rectangle(text_bbox, fill = color)\n",
    "            draw.text((x1, y1-5), label, fill = (255, 255, 255), font = font)\n",
    "    \n",
    "                \n",
    "    img0 = Image.alpha_composite(img0, layer)\n",
    "    #display(img0)\n",
    "    #img0.save(\"Detection0.png\")\n",
    "    #plot_results(img0, inference_state)\n",
    "    \n",
    "    # 2. Detect and decode the Code128 barcodes of the requested objects and compute their normal surface vector: #\n",
    "    processor.reset_all_prompts(inference_state)\n",
    "    inference_state = processor.set_text_prompt(state = inference_state, prompt = \"tight crop of black vertical barcode lines, ink pattern only\")\n",
    "    \n",
    "    img1 = input_image.convert(\"RGBA\")\n",
    "    img1_gray = img1.convert(\"L\")\n",
    "    img1_gray = np.array(img1_gray)\n",
    "    layer = Image.new(\"RGBA\", img1.size, (0, 0, 0, 0))\n",
    "    draw = ImageDraw.Draw(layer)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 40)\n",
    "    \n",
    "    boxes = inference_state[\"boxes\"]\n",
    "    masks = inference_state[\"masks\"]\n",
    "\n",
    "    barcode_map = {}\n",
    "    \n",
    "    for k, barcode in enumerate(inference_state[\"boxes\"]):\n",
    "        # COLOR\n",
    "        rgb = colorsys.hsv_to_rgb(k / len(boxes), 1.0, 1.0) \n",
    "        r, g, b = int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255)\n",
    "        color = (r, g, b)\n",
    "    \n",
    "        # Barcode Coordinates\n",
    "        bcx1, bcy1, bcx2, bcy2 = barcode[0].item(), barcode[1].item(), barcode[2].item(), barcode[3].item()\n",
    "        bc_center_x = (bcx1 + bcx2) / 2\n",
    "        bc_center_y = (bcy1 + bcy2) / 2\n",
    "        \n",
    "        # Barcode's Item\n",
    "        for name, item in box_map.items():\n",
    "            ix1, iy1, ix2, iy2 = item\n",
    "            if ix1 < bc_center_x < ix2 and iy1 < bc_center_y < iy2:\n",
    "                # Rectangle\n",
    "                draw.rectangle((bcx1, bcy1, bcx2, bcy2), outline = color, width = 5)  \n",
    "    \n",
    "                # Mask\n",
    "                mask_data = masks[k].cpu().numpy()            \n",
    "                mask_data = (mask_data > 0).astype('uint8') * 255\n",
    "                if mask_data.ndim > 2: mask_data = mask_data[0]   \n",
    "                mask_image = Image.fromarray(mask_data, mode = \"L\") \n",
    "                solid_color = Image.new(\"RGBA\", img1.size, color + (100,)) \n",
    "                layer.paste(solid_color, (0,0), mask_image)\n",
    "    \n",
    "                # Cropped Barcode\n",
    "                crop_bar = crop_barcode(img1_gray, mask_data)\n",
    "                barcode_value = bar_value(crop_bar)\n",
    "                barcode_map[name] = barcode_value\n",
    "                #barcode_mao[barcode_value] = name\n",
    "                \n",
    "                #display(Image.fromarray(crop_bar))\n",
    "                #crop_bar.save(\"Normal_Barcode.png\")\n",
    "                #print(name, \": \", barcode_value)\n",
    "     \n",
    "                # Text\n",
    "                label = f\"{name} {k}\" # Put the barcode number \n",
    "                text_bbox = draw.textbbox((bcx1, bcy1-5), label, font = font)\n",
    "                draw.rectangle(text_bbox, fill = color)\n",
    "                draw.text((bcx1, bcy1-5), label, fill = (255, 255, 255), font = font)\n",
    "                \n",
    "                # Normal vector            \n",
    "                mask_n = masks[k].cpu().numpy()\n",
    "                if mask_n.ndim > 2: mask_n = mask_n[0]\n",
    "                y_row, x_column = np.nonzero(mask_n > 0)\n",
    "                coords = np.stack([x_column, y_row], axis = 1) # Matrix\n",
    "                \n",
    "                cov = np.cov(coords.T) # Covariance Matrix\n",
    "                    \n",
    "                evals, evecs = np.linalg.eig(cov) # Eigenvalues and Eigenvectors\n",
    "    \n",
    "                min_eval = np.argmin(evals) # The normal vector corresponds to the lowest eigenvalue\n",
    "                normal_v = evecs[:, min_eval] # This is the normal axis\n",
    "    \n",
    "                magnitude = np.sqrt(evals[min_eval]) \n",
    "                arrow_len = magnitude * 2.0\n",
    "    \n",
    "                parent_cx = (ix1 + ix2) / 2\n",
    "                parent_cy = (iy1 + iy2) / 2\n",
    "    \n",
    "                # Vector that goes from the center of the item to the center of its barcode\n",
    "                vec_outward = np.array([bc_center_x - parent_cx, bc_center_y - parent_cy]) \n",
    "                \n",
    "                # If they go in a \"similar direction\", their dot product is positive; else is negative.\n",
    "                # Since the items are objects, if you go from the center to the surface (barcode) you are going outwards of the object\n",
    "                # That's why the normal vector goes in the same direction as the one that goes from the center to the surface (the outwards vector)\n",
    "                if np.dot(normal_v, vec_outward) < 0:\n",
    "                    normal_v = -normal_v\n",
    "                    \n",
    "                p_end_x = bc_center_x + normal_v[0] * arrow_len\n",
    "                p_end_y = bc_center_y + normal_v[1] * arrow_len\n",
    "    \n",
    "                # The absence of depht information makes really difficult the calculation of the normal vector\n",
    "                draw.line([(bc_center_x, bc_center_y), (p_end_x, p_end_y)], fill = \"black\", width = 4)        \n",
    "                draw.ellipse((p_end_x - 8, p_end_y - 8, p_end_x + 8, p_end_y + 8), fill = \"black\")\n",
    "    \n",
    "    img1 = Image.alpha_composite(img1, layer)\n",
    "    \n",
    "    if word == \"Croc\": rel = \"Shoe\"\n",
    "    elif word == \"Spanner\": rel = \"Wrench\"\n",
    "    elif word == \"X001BZ87F1\": rel = \"Box\"\n",
    "    else: rel = word\n",
    "    \n",
    "    print(\"______\")\n",
    "    print(\"OUTPUT\")\n",
    "    print(\"______\")\n",
    "    print()\n",
    "    print(\"Detect and Identify the Listed Items\")\n",
    "    display(img0)\n",
    "    print()\n",
    "    print(\"Barcodes's Detection and Normal Vector\")\n",
    "    display(img1)\n",
    "    print()\n",
    "    print(\"Relationship\")\n",
    "    print(word, \"->\", rel)\n",
    "    print(\"______\")\n",
    "\n",
    "    return img0, img1, word\n",
    "    #img0.save(\"Normal_Barcode.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4797360e-b660-4ed4-ba05-be99f63b9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title = \"SAM3 Barcode Detector\") as demo:\n",
    "    gr.Markdown(\"# üïµÔ∏è SAM3 Object & Barcode Detector\")\n",
    "    gr.Markdown(\"Upload an image and list the objects\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            in_image = gr.Image(type = \"pil\", label = \"Imatge Input\")\n",
    "            in_text1 = gr.Textbox(label = \"Objects to detect (first capital letter and separated by a comma)\", \n",
    "                                 value = \"Bottle, Box, Mug, Spanner, Scissors, Screwdriver, Croc\")\n",
    "            in_text2 = gr.Textbox(label = \"Object vs Barcode\", value = \"Bottle\")\n",
    "            btn = gr.Button(\"Analyzse\", variant = \"primary\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            out_image_1 = gr.Image(type = \"pil\", label = \"Object Detection Output\")\n",
    "            out_image_2 = gr.Image(type = \"pil\", label = \"Barcodes and Normal Vector Output\")\n",
    "            out_text = gr.Textbox(label = \"Object vs Barcode\")\n",
    "\n",
    "\n",
    "    btn.click(fn = process_image, inputs = [in_image, in_text1, in_text2], outputs = [out_image_1, out_image_2, out_text])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share = True)"
   ]
  }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python (SAM 3 Project)",
    "language": "python",
    "name": "sam3_project"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.12.12"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 }
